# ðŸ§  Neural Network

------------------------------------------------------------------------

## ðŸ“Œ 1. What is a Neural Network?

A Neural Network is a system that learns patterns by adjusting numbers
called **weights**.

Think of it as:

Input â†’ Hidden Thinking â†’ Final Decision

------------------------------------------------------------------------

## ðŸ–¼ Structure of a Neural Network

![Neural Network Structure](Md_IMG/n1.png)
image source:Geeks for Geeks

-   Input Layer â†’ receives data\
-   Hidden Layer â†’ processes data\
-   Output Layer â†’ gives prediction

------------------------------------------------------------------------

## ðŸ“Œ 2. Analogy (Real Life)

Imagine preparing tea â˜•

-   Ingredients â†’ Inputs\
-   Quantity adjustments â†’ Weights\
-   Extra sugar â†’ Bias\
-   Taste test â†’ Activation\
-   Final flavor â†’ Output

If taste is bad â†’ adjust ingredients â†’ try again

That adjustment process = learning.

------------------------------------------------------------------------

## ðŸ“Œ 3. Forward Propagation (Python Formulas)

### Step 1: Hidden Layer

``` python
z1 = W1 @ x + b1
a1 = relu(z1)
```

### Step 2: Output Layer

``` python
z2 = W2 @ a1 + b2
y_hat = sigmoid(z2)
```

------------------------------------------------------------------------

## ðŸ–¼ Forward Flow

![Forward Flow](Md_IMG/w2.png)

------------------------------------------------------------------------

## ðŸ“Œ 4. Activation Functions (Python)

``` python
def relu(z):
    return np.maximum(0, z)

def sigmoid(z):
    return 1 / (1 + np.exp(-z))
```

------------------------------------------------------------------------

## ðŸ“Œ 5. Loss Function

``` python
loss = 0.5 * (y - y_hat)**2
```

------------------------------------------------------------------------

## ðŸ“Œ 6. Backpropagation (Core Python Formulas)

``` python
# Output layer gradient
dL_dyhat = -(y - y_hat)
dyhat_dz2 = y_hat * (1 - y_hat)

delta2 = dL_dyhat * dyhat_dz2
dW2 = delta2 @ a1.T
db2 = delta2

# Hidden layer gradient
delta1 = (W2.T @ delta2) * (a1 > 0)
dW1 = delta1 @ x.T
db1 = delta1
```

------------------------------------------------------------------------

## ðŸ“Œ 7. Weight Update Rule

``` python
W1 -= lr * dW1
b1 -= lr * db1
W2 -= lr * dW2
b2 -= lr * db2
```

------------------------------------------------------------------------

## ðŸŽ¯ Final Idea

Neural Network =

Linear math,then\
+ Activation,then\
+ Error calculation,then\
+ Small improvements repeated many times,until

Eventually good predictions or outcomes occur then we say that the model is trained ðŸŽ¯

------------------------------------------------------------------------

**Author: Karthik S Nair**